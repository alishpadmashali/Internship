{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4dbfcfe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "import time\n",
    "import pandas as pd\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.webdriver.common.by import By"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca7ef9a1",
   "metadata": {},
   "source": [
    "# Question No- 07------IMDB Series\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77685915",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome() \n",
    "driver.get(\"http://www.imdb.com/list/ls095964455/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "791ca764",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets Scrape the name of the series\n",
    "\n",
    "Series_Name=[]\n",
    "\n",
    "Name=driver.find_elements(By.XPATH,'//div[@class=\"lister-item mode-detail\"]/div[2]/h3[1]/a[1]')\n",
    "for a in Name:\n",
    "    Name1=a.text\n",
    "    Series_Name.append(Name1)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "#Lets Scrape the year of the series\n",
    "\n",
    "Year_Span=[]\n",
    "\n",
    "YS=driver.find_elements(By.XPATH,'//div[@class=\"lister-item mode-detail\"]/div[2]/h3[1]/span[2]')\n",
    "for b in YS:\n",
    "    yp=b.text\n",
    "    Year_Span.append(yp)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "#Lets Scrape the Genre of the series\n",
    "\n",
    "Genre=[]\n",
    "\n",
    "Genre1=driver.find_elements(By.XPATH,'//div[@class=\"lister-item mode-detail\"]/div[2]/p[1]/span[5]')\n",
    "for c in Genre1:\n",
    "    Gn=c.text\n",
    "    Genre.append(Gn)\n",
    "    \n",
    "    \n",
    "    \n",
    "#Lets Scrape the Run time of the series\n",
    "\n",
    "Run_Time=[]\n",
    "\n",
    "RT=driver.find_elements(By.XPATH,'//div[@class=\"lister-item mode-detail\"]/div[2]/p[1]/span[3]')\n",
    "for d in RT:\n",
    "    RT1=d.text\n",
    "    Run_Time.append(RT1)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "#Lets Scrape the Ratings of the series\n",
    "\n",
    "Ratings=[]\n",
    "\n",
    "Rate=driver.find_elements(By.XPATH,'//div[@class=\"lister-item mode-detail\"]/div[2]/div[1]/div[1]/span[2]')\n",
    "for e in Rate:\n",
    "    Rate1=e.text\n",
    "    Ratings.append(Rate1)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "#Lets Scrape the Votes of the series\n",
    "\n",
    "Votes=[]\n",
    "\n",
    "vote=driver.find_elements(By.XPATH,'//div[@class=\"lister-item mode-detail\"]/div[2]/p[4]/span[2]')\n",
    "for f in vote:\n",
    "    vote1=f.text\n",
    "    Votes.append(vote1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eb48c861",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Year</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Run time</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Votes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Game of Thrones</td>\n",
       "      <td>(2011‚Äì2019)</td>\n",
       "      <td>Action, Adventure, Drama</td>\n",
       "      <td>57 min</td>\n",
       "      <td>9.2</td>\n",
       "      <td>2,193,044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stranger Things</td>\n",
       "      <td>(2016‚Äì2024)</td>\n",
       "      <td>Drama, Fantasy, Horror</td>\n",
       "      <td>51 min</td>\n",
       "      <td>8.7</td>\n",
       "      <td>1,266,805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Walking Dead</td>\n",
       "      <td>(2010‚Äì2022)</td>\n",
       "      <td>Drama, Horror, Thriller</td>\n",
       "      <td>44 min</td>\n",
       "      <td>8.1</td>\n",
       "      <td>1,040,947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13 Reasons Why</td>\n",
       "      <td>(2017‚Äì2020)</td>\n",
       "      <td>Drama, Mystery, Thriller</td>\n",
       "      <td>60 min</td>\n",
       "      <td>7.5</td>\n",
       "      <td>305,958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The 100</td>\n",
       "      <td>(2014‚Äì2020)</td>\n",
       "      <td>Drama, Mystery, Sci-Fi</td>\n",
       "      <td>43 min</td>\n",
       "      <td>7.6</td>\n",
       "      <td>265,028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Reign</td>\n",
       "      <td>(2013‚Äì2017)</td>\n",
       "      <td>Drama</td>\n",
       "      <td>42 min</td>\n",
       "      <td>7.4</td>\n",
       "      <td>52,423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>A Series of Unfortunate Events</td>\n",
       "      <td>(2017‚Äì2019)</td>\n",
       "      <td>Adventure, Comedy, Drama</td>\n",
       "      <td>50 min</td>\n",
       "      <td>7.8</td>\n",
       "      <td>64,452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Criminal Minds</td>\n",
       "      <td>(2005‚Äì )</td>\n",
       "      <td>Crime, Drama, Mystery</td>\n",
       "      <td>42 min</td>\n",
       "      <td>8.1</td>\n",
       "      <td>210,096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Scream: The TV Series</td>\n",
       "      <td>(2015‚Äì2019)</td>\n",
       "      <td>Comedy, Crime, Drama</td>\n",
       "      <td>45 min</td>\n",
       "      <td>7</td>\n",
       "      <td>43,685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>The Haunting of Hill House</td>\n",
       "      <td>(2018)</td>\n",
       "      <td>Drama, Horror, Mystery</td>\n",
       "      <td>572 min</td>\n",
       "      <td>8.6</td>\n",
       "      <td>263,653</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows √ó 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Name         Year                     Genre  \\\n",
       "0                  Game of Thrones  (2011‚Äì2019)  Action, Adventure, Drama   \n",
       "1                  Stranger Things  (2016‚Äì2024)    Drama, Fantasy, Horror   \n",
       "2                 The Walking Dead  (2010‚Äì2022)   Drama, Horror, Thriller   \n",
       "3                   13 Reasons Why  (2017‚Äì2020)  Drama, Mystery, Thriller   \n",
       "4                          The 100  (2014‚Äì2020)    Drama, Mystery, Sci-Fi   \n",
       "..                             ...          ...                       ...   \n",
       "95                           Reign  (2013‚Äì2017)                     Drama   \n",
       "96  A Series of Unfortunate Events  (2017‚Äì2019)  Adventure, Comedy, Drama   \n",
       "97                  Criminal Minds     (2005‚Äì )     Crime, Drama, Mystery   \n",
       "98           Scream: The TV Series  (2015‚Äì2019)      Comedy, Crime, Drama   \n",
       "99      The Haunting of Hill House       (2018)    Drama, Horror, Mystery   \n",
       "\n",
       "   Run time Ratings      Votes  \n",
       "0    57 min     9.2  2,193,044  \n",
       "1    51 min     8.7  1,266,805  \n",
       "2    44 min     8.1  1,040,947  \n",
       "3    60 min     7.5    305,958  \n",
       "4    43 min     7.6    265,028  \n",
       "..      ...     ...        ...  \n",
       "95   42 min     7.4     52,423  \n",
       "96   50 min     7.8     64,452  \n",
       "97   42 min     8.1    210,096  \n",
       "98   45 min       7     43,685  \n",
       "99  572 min     8.6    263,653  \n",
       "\n",
       "[100 rows x 6 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame({'Name':Series_Name,'Year':Year_Span,'Genre': Genre,'Run time':Run_Time,'Ratings':Ratings,'Votes':Votes})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c10073a2",
   "metadata": {},
   "source": [
    "# Question No 2----------BCCI India tean schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "72cf813f",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome()\n",
    "driver.get('http://www.bcci.tv/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2ae214d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Domestic=driver.find_element(By.XPATH,\"/html/body/nav/div[1]/div[2]/ul[1]/li[2]/a\")\n",
    "Domestic.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "04d06fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets Scrape the Match Title of the series\n",
    "\n",
    "Title=[]\n",
    "\n",
    "Mtitle=driver.find_elements(By.XPATH,'//div[@class=\"match-card ng-scope\"]/div[1]/h5[1]')\n",
    "for a1 in Mtitle:\n",
    "    title=a1.text\n",
    "    Title.append(title)\n",
    "    \n",
    "    \n",
    "    \n",
    "#Lets scrape the series \n",
    "\n",
    "\n",
    "Series=[]\n",
    "\n",
    "Ser=driver.find_elements(By.XPATH,'//div[@class=\"match-card ng-scope\"]/div[3]/div[1]/span[1]')\n",
    "for b1 in Ser:\n",
    "    ser=b1.text\n",
    "    Series.append(ser)\n",
    "    \n",
    "    \n",
    "#Lets Scrape the place\n",
    "\n",
    "\n",
    "Place1=[]\n",
    "\n",
    "\n",
    "pl=driver.find_elements(By.XPATH,'//div[@class=\"match-card ng-scope\"]/div[3]/div[1]')\n",
    "\n",
    "for c1 in pl:\n",
    "    plac=c1.text.split('-')[1]\n",
    "    Place1.append(plac)\n",
    "    \n",
    "    \n",
    "#lets scrape the date \n",
    "\n",
    "\n",
    "Date=[]\n",
    "\n",
    "date=driver.find_elements(By.XPATH,'//div[@class=\"match-card ng-scope\"]/div[1]/div[1]/div[1]')\n",
    "\n",
    "for d1 in date:\n",
    "    datee=d1.text\n",
    "    Date.append(datee)\n",
    "    \n",
    "    \n",
    "    \n",
    "#lets scrape the date \n",
    "\n",
    "\n",
    "Time=[]\n",
    "\n",
    "time=driver.find_elements(By.XPATH,'//div[@class=\"match-card ng-scope\"]/div[1]/div[1]/div[2]')\n",
    "\n",
    "for e1 in time:\n",
    "    timee=e1.text\n",
    "    Time.append(timee)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "506f1d66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Match Title</th>\n",
       "      <th>Series</th>\n",
       "      <th>Place</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1st T20I -</td>\n",
       "      <td>INDIA TOUR OF IRELAND 2023</td>\n",
       "      <td>The Village, Dublin</td>\n",
       "      <td>18 AUG 2023</td>\n",
       "      <td>7:30 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2nd T20I -</td>\n",
       "      <td>INDIA TOUR OF IRELAND 2023</td>\n",
       "      <td>The Village, Dublin</td>\n",
       "      <td>20 AUG 2023</td>\n",
       "      <td>7:30 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3rd T20I -</td>\n",
       "      <td>INDIA TOUR OF IRELAND 2023</td>\n",
       "      <td>The Village, Dublin</td>\n",
       "      <td>23 AUG 2023</td>\n",
       "      <td>7:30 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1st ODI -</td>\n",
       "      <td>ASIA CUP 2023</td>\n",
       "      <td>Pallekele International Cricket Stadium, Pall...</td>\n",
       "      <td>2 SEP 2023</td>\n",
       "      <td>10:00 AM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2nd ODI -</td>\n",
       "      <td>ASIA CUP 2023</td>\n",
       "      <td>Pallekele International Cricket Stadium, Pall...</td>\n",
       "      <td>4 SEP 2023</td>\n",
       "      <td>10:00 AM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1st ODI -</td>\n",
       "      <td>AUSTRALIA TOUR OF INDIA 2023-24</td>\n",
       "      <td>Punjab Cricket Association IS Bindra Stadium,...</td>\n",
       "      <td>22 SEP 2023</td>\n",
       "      <td>1:30 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2nd ODI -</td>\n",
       "      <td>AUSTRALIA TOUR OF INDIA 2023-24</td>\n",
       "      <td>Holkar Cricket Stadium, Indore</td>\n",
       "      <td>24 SEP 2023</td>\n",
       "      <td>1:30 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3rd ODI -</td>\n",
       "      <td>AUSTRALIA TOUR OF INDIA 2023-24</td>\n",
       "      <td>Saurashtra Cricket Association Stadium, Rajkot</td>\n",
       "      <td>27 SEP 2023</td>\n",
       "      <td>1:30 PM IST</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Match Title                           Series  \\\n",
       "0  1st T20I -       INDIA TOUR OF IRELAND 2023   \n",
       "1  2nd T20I -       INDIA TOUR OF IRELAND 2023   \n",
       "2  3rd T20I -       INDIA TOUR OF IRELAND 2023   \n",
       "3   1st ODI -                    ASIA CUP 2023   \n",
       "4   2nd ODI -                    ASIA CUP 2023   \n",
       "5   1st ODI -  AUSTRALIA TOUR OF INDIA 2023-24   \n",
       "6   2nd ODI -  AUSTRALIA TOUR OF INDIA 2023-24   \n",
       "7   3rd ODI -  AUSTRALIA TOUR OF INDIA 2023-24   \n",
       "\n",
       "                                               Place         Date  \\\n",
       "0                                The Village, Dublin  18 AUG 2023   \n",
       "1                                The Village, Dublin  20 AUG 2023   \n",
       "2                                The Village, Dublin  23 AUG 2023   \n",
       "3   Pallekele International Cricket Stadium, Pall...   2 SEP 2023   \n",
       "4   Pallekele International Cricket Stadium, Pall...   4 SEP 2023   \n",
       "5   Punjab Cricket Association IS Bindra Stadium,...  22 SEP 2023   \n",
       "6                     Holkar Cricket Stadium, Indore  24 SEP 2023   \n",
       "7     Saurashtra Cricket Association Stadium, Rajkot  27 SEP 2023   \n",
       "\n",
       "           Time  \n",
       "0   7:30 PM IST  \n",
       "1   7:30 PM IST  \n",
       "2   7:30 PM IST  \n",
       "3  10:00 AM IST  \n",
       "4  10:00 AM IST  \n",
       "5   1:30 PM IST  \n",
       "6   1:30 PM IST  \n",
       "7   1:30 PM IST  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2=pd.DataFrame({'Match Title':Series,'Series':Title,'Place':Place1,'Date':Date,'Time':Time})\n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78c6e532",
   "metadata": {},
   "source": [
    "# Question No3----State GDP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2dfcd38f",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome()\n",
    "driver.get('http://statisticstimes.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "52e6fe46",
   "metadata": {},
   "outputs": [],
   "source": [
    "Economy=driver.find_element(By.XPATH,'/html/body/div[2]/div[1]/div[2]/div[2]/button')\n",
    "Economy.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c019a6dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "Economy_ind=driver.find_element(By.XPATH,'/html/body/div[2]/div[2]/div[2]/ul/li[1]/a')\n",
    "Economy_ind.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "85a6dcf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets scrape the State Name \n",
    "State=[]\n",
    "\n",
    "state=driver.find_elements(By.XPATH,'//table[@class=\"display dataTable\"]/tbody[1]/tr/td[2]')\n",
    "\n",
    "for aa in state:\n",
    "    state1=aa.text\n",
    "    State.append(state1)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "#lets scrape the GDP1 \n",
    "GDP_18_19=[]\n",
    "\n",
    "GDP1=driver.find_elements(By.XPATH,'//table[@class=\"display dataTable\"]/tbody[1]/tr/td[4]')\n",
    "\n",
    "for bb in GDP1:\n",
    "    gdp1=bb.text\n",
    "    GDP_18_19.append(gdp1)\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "#lets scrape the Share\n",
    "Shares=[]\n",
    "\n",
    "share=driver.find_elements(By.XPATH,'//table[@class=\"display dataTable\"]/tbody[1]/tr/td[5]')\n",
    "\n",
    "for dd in share:\n",
    "    share1=dd.text\n",
    "    Shares.append(share1)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "#lets scrape the GDP2\n",
    "GDP_19_20=[]\n",
    "\n",
    "GDP2=driver.find_elements(By.XPATH,'//table[@class=\"display dataTable\"]/tbody[1]/tr/td[3]')\n",
    "\n",
    "for bb in GDP2:\n",
    "    gdp2=bb.text\n",
    "    GDP_19_20.append(gdp2)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "#lets scrape the GDP_Billion\n",
    "GDP_Billion=[]\n",
    "\n",
    "gdp=driver.find_elements(By.XPATH,'//table[@class=\"display dataTable\"]/tbody[1]/tr/td[6]')\n",
    "\n",
    "for ee in gdp:\n",
    "    gdp1=ee.text\n",
    "    GDP_Billion.append(gdp1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "de00866c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(State)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9febd01e",
   "metadata": {},
   "outputs": [],
   "source": [
    "State1=State[:33]\n",
    "GDP_18_191=GDP_18_19[:33]\n",
    "GDP_Billion1=GDP_Billion[:33]\n",
    "GDP_19_201=GDP_19_20[:33]\n",
    "Shares1=Shares[:33]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5d0b3ffa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>GDP_18_19</th>\n",
       "      <th>GDP_19_20</th>\n",
       "      <th>GDP_Billion</th>\n",
       "      <th>Shares</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Maharashtra</td>\n",
       "      <td>2,632,792</td>\n",
       "      <td>-</td>\n",
       "      <td>399.921</td>\n",
       "      <td>13.94%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tamil Nadu</td>\n",
       "      <td>1,630,208</td>\n",
       "      <td>1,845,853</td>\n",
       "      <td>247.629</td>\n",
       "      <td>8.63%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Uttar Pradesh</td>\n",
       "      <td>1,584,764</td>\n",
       "      <td>1,687,818</td>\n",
       "      <td>240.726</td>\n",
       "      <td>8.39%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gujarat</td>\n",
       "      <td>1,502,899</td>\n",
       "      <td>-</td>\n",
       "      <td>228.290</td>\n",
       "      <td>7.96%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Karnataka</td>\n",
       "      <td>1,493,127</td>\n",
       "      <td>1,631,977</td>\n",
       "      <td>226.806</td>\n",
       "      <td>7.91%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>West Bengal</td>\n",
       "      <td>1,089,898</td>\n",
       "      <td>1,253,832</td>\n",
       "      <td>165.556</td>\n",
       "      <td>5.77%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Rajasthan</td>\n",
       "      <td>942,586</td>\n",
       "      <td>1,020,989</td>\n",
       "      <td>143.179</td>\n",
       "      <td>4.99%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Andhra Pradesh</td>\n",
       "      <td>862,957</td>\n",
       "      <td>972,782</td>\n",
       "      <td>131.083</td>\n",
       "      <td>4.57%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Telangana</td>\n",
       "      <td>861,031</td>\n",
       "      <td>969,604</td>\n",
       "      <td>130.791</td>\n",
       "      <td>4.56%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Madhya Pradesh</td>\n",
       "      <td>809,592</td>\n",
       "      <td>906,672</td>\n",
       "      <td>122.977</td>\n",
       "      <td>4.29%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Kerala</td>\n",
       "      <td>781,653</td>\n",
       "      <td>-</td>\n",
       "      <td>118.733</td>\n",
       "      <td>4.14%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Delhi</td>\n",
       "      <td>774,870</td>\n",
       "      <td>856,112</td>\n",
       "      <td>117.703</td>\n",
       "      <td>4.10%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Haryana</td>\n",
       "      <td>734,163</td>\n",
       "      <td>831,610</td>\n",
       "      <td>111.519</td>\n",
       "      <td>3.89%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Bihar</td>\n",
       "      <td>530,363</td>\n",
       "      <td>611,804</td>\n",
       "      <td>80.562</td>\n",
       "      <td>2.81%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Punjab</td>\n",
       "      <td>526,376</td>\n",
       "      <td>574,760</td>\n",
       "      <td>79.957</td>\n",
       "      <td>2.79%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Odisha</td>\n",
       "      <td>487,805</td>\n",
       "      <td>521,275</td>\n",
       "      <td>74.098</td>\n",
       "      <td>2.58%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Assam</td>\n",
       "      <td>315,881</td>\n",
       "      <td>-</td>\n",
       "      <td>47.982</td>\n",
       "      <td>1.67%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Chhattisgarh</td>\n",
       "      <td>304,063</td>\n",
       "      <td>329,180</td>\n",
       "      <td>46.187</td>\n",
       "      <td>1.61%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Jharkhand</td>\n",
       "      <td>297,204</td>\n",
       "      <td>328,598</td>\n",
       "      <td>45.145</td>\n",
       "      <td>1.57%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Uttarakhand</td>\n",
       "      <td>245,895</td>\n",
       "      <td>-</td>\n",
       "      <td>37.351</td>\n",
       "      <td>1.30%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Jammu &amp; Kashmir</td>\n",
       "      <td>155,956</td>\n",
       "      <td>-</td>\n",
       "      <td>23.690</td>\n",
       "      <td>0.83%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Himachal Pradesh</td>\n",
       "      <td>153,845</td>\n",
       "      <td>165,472</td>\n",
       "      <td>23.369</td>\n",
       "      <td>0.81%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Goa</td>\n",
       "      <td>73,170</td>\n",
       "      <td>80,449</td>\n",
       "      <td>11.115</td>\n",
       "      <td>0.39%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Tripura</td>\n",
       "      <td>49,845</td>\n",
       "      <td>55,984</td>\n",
       "      <td>7.571</td>\n",
       "      <td>0.26%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Chandigarh</td>\n",
       "      <td>42,114</td>\n",
       "      <td>-</td>\n",
       "      <td>6.397</td>\n",
       "      <td>0.22%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Puducherry</td>\n",
       "      <td>34,433</td>\n",
       "      <td>38,253</td>\n",
       "      <td>5.230</td>\n",
       "      <td>0.18%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Meghalaya</td>\n",
       "      <td>33,481</td>\n",
       "      <td>36,572</td>\n",
       "      <td>5.086</td>\n",
       "      <td>0.18%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Sikkim</td>\n",
       "      <td>28,723</td>\n",
       "      <td>32,496</td>\n",
       "      <td>4.363</td>\n",
       "      <td>0.15%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Manipur</td>\n",
       "      <td>27,870</td>\n",
       "      <td>31,790</td>\n",
       "      <td>4.233</td>\n",
       "      <td>0.15%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Nagaland</td>\n",
       "      <td>27,283</td>\n",
       "      <td>-</td>\n",
       "      <td>4.144</td>\n",
       "      <td>0.14%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Arunachal Pradesh</td>\n",
       "      <td>24,603</td>\n",
       "      <td>-</td>\n",
       "      <td>3.737</td>\n",
       "      <td>0.13%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Mizoram</td>\n",
       "      <td>22,287</td>\n",
       "      <td>26,503</td>\n",
       "      <td>3.385</td>\n",
       "      <td>0.12%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Andaman &amp; Nicobar Islands</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        State  GDP_18_19  GDP_19_20 GDP_Billion  Shares\n",
       "0                 Maharashtra  2,632,792          -     399.921  13.94%\n",
       "1                  Tamil Nadu  1,630,208  1,845,853     247.629   8.63%\n",
       "2               Uttar Pradesh  1,584,764  1,687,818     240.726   8.39%\n",
       "3                     Gujarat  1,502,899          -     228.290   7.96%\n",
       "4                   Karnataka  1,493,127  1,631,977     226.806   7.91%\n",
       "5                 West Bengal  1,089,898  1,253,832     165.556   5.77%\n",
       "6                   Rajasthan    942,586  1,020,989     143.179   4.99%\n",
       "7              Andhra Pradesh    862,957    972,782     131.083   4.57%\n",
       "8                   Telangana    861,031    969,604     130.791   4.56%\n",
       "9              Madhya Pradesh    809,592    906,672     122.977   4.29%\n",
       "10                     Kerala    781,653          -     118.733   4.14%\n",
       "11                      Delhi    774,870    856,112     117.703   4.10%\n",
       "12                    Haryana    734,163    831,610     111.519   3.89%\n",
       "13                      Bihar    530,363    611,804      80.562   2.81%\n",
       "14                     Punjab    526,376    574,760      79.957   2.79%\n",
       "15                     Odisha    487,805    521,275      74.098   2.58%\n",
       "16                      Assam    315,881          -      47.982   1.67%\n",
       "17               Chhattisgarh    304,063    329,180      46.187   1.61%\n",
       "18                  Jharkhand    297,204    328,598      45.145   1.57%\n",
       "19                Uttarakhand    245,895          -      37.351   1.30%\n",
       "20            Jammu & Kashmir    155,956          -      23.690   0.83%\n",
       "21           Himachal Pradesh    153,845    165,472      23.369   0.81%\n",
       "22                        Goa     73,170     80,449      11.115   0.39%\n",
       "23                    Tripura     49,845     55,984       7.571   0.26%\n",
       "24                 Chandigarh     42,114          -       6.397   0.22%\n",
       "25                 Puducherry     34,433     38,253       5.230   0.18%\n",
       "26                  Meghalaya     33,481     36,572       5.086   0.18%\n",
       "27                     Sikkim     28,723     32,496       4.363   0.15%\n",
       "28                    Manipur     27,870     31,790       4.233   0.15%\n",
       "29                   Nagaland     27,283          -       4.144   0.14%\n",
       "30          Arunachal Pradesh     24,603          -       3.737   0.13%\n",
       "31                    Mizoram     22,287     26,503       3.385   0.12%\n",
       "32  Andaman & Nicobar Islands          -          -           -       -"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3=pd.DataFrame({'State':State1,'GDP_18_19':GDP_18_191,'GDP_19_20':GDP_19_201,'GDP_Billion':GDP_Billion1,'Shares':Shares1})\n",
    "df3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b4e6975",
   "metadata": {},
   "source": [
    "# Question No 04-------Github Trending Repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "45c735ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome()\n",
    "driver.get('https://github.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ca615bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Click open source\n",
    "\n",
    "Open=driver.find_element(By.XPATH,'/html/body/div[1]/div[1]/header/div/div[2]/div/nav/ul/li[3]/button')\n",
    "Open.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ed0f64e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets scrape the Repository title\n",
    "Repository_title=[]\n",
    "\n",
    "Rep=driver.find_elements(By.XPATH,'//article[@class=\"Box-row\"]/h2[1]')\n",
    "\n",
    "for a0 in Rep:\n",
    "    rep1=a0.text\n",
    "    Repository_title.append(rep1)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "#lets scrape the Repository description\n",
    "Repository_description=[]\n",
    "\n",
    "Des=driver.find_elements(By.XPATH,'//article[@class=\"Box-row\"]/p[1]')\n",
    "\n",
    "for b0 in Des:\n",
    "    Des1=b0.text\n",
    "    Repository_description.append(Des1)\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "#lets scrape the Language\n",
    "Language=[]\n",
    "\n",
    "lan=driver.find_elements(By.XPATH,'//article[@class=\"Box-row\"]/div[2]/span[1]')\n",
    "\n",
    "for c0 in lan:\n",
    "    lan1=c0.text\n",
    "    Language.append(lan1)\n",
    "    \n",
    "    \n",
    "#lets scrape the url and Contributor count\n",
    "product_url1=[]\n",
    "\n",
    "url=driver.find_elements(By.XPATH,'//a[@class=\"Link\"]')\n",
    "for i in url:\n",
    "    product_url1.append(i.get_attribute('href'))\n",
    "time.sleep(3)\n",
    "\n",
    "\n",
    "\n",
    "#lets scrape the Contributor\n",
    "\n",
    "Contributor=[]\n",
    "\n",
    "for url in product_url1:\n",
    "    driver.get(url)\n",
    "    time.sleep(3)\n",
    "    try:\n",
    "        Cont1=driver.find_element(By.XPATH,'//div[@class=\"BorderGrid BorderGrid--spacious\"]/div[4]/div[1]/h2[1]/a[1]/span[1]')\n",
    "        Contributor.append(Cont1.text)\n",
    "    except NoSuchElementException:\n",
    "        Contributor.append('-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "827a1fc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Repository title</th>\n",
       "      <th>Repository description</th>\n",
       "      <th>Contributor</th>\n",
       "      <th>Language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>getumbrel / llama-gpt</td>\n",
       "      <td>A self-hosted, offline, ChatGPT-like chatbot. ...</td>\n",
       "      <td>-</td>\n",
       "      <td>TypeScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>elidianaandrade / dio-lab-open-source</td>\n",
       "      <td>Reposit√≥rio do lab Contribuindo em um Projeto ...</td>\n",
       "      <td>-</td>\n",
       "      <td>Built by</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>apple / ml-fastvit</td>\n",
       "      <td>This repository contains the official implemen...</td>\n",
       "      <td>2</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>alibaba / canal</td>\n",
       "      <td>ÈòøÈáåÂ∑¥Â∑¥ MySQL binlog Â¢ûÈáèËÆ¢ÈòÖ&amp;Ê∂àË¥πÁªÑ‰ª∂</td>\n",
       "      <td>2</td>\n",
       "      <td>Java</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LorisYounger / VPet</td>\n",
       "      <td>ËôöÊãüÊ°åÂÆ†Ê®°ÊãüÂô® ‰∏Ä‰∏™ÂºÄÊ∫êÁöÑÊ°åÂÆ†ËΩØ‰ª∂, ÂèØ‰ª•ÂÜÖÁΩÆÂà∞‰ªª‰ΩïWPFÂ∫îÁî®Á®ãÂ∫è</td>\n",
       "      <td>1</td>\n",
       "      <td>C#</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>systeminit / si</td>\n",
       "      <td>The System Initiative software</td>\n",
       "      <td>-</td>\n",
       "      <td>Rust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ubicloud / ubicloud</td>\n",
       "      <td>Open, free, and portable cloud. Elastic comput...</td>\n",
       "      <td>8</td>\n",
       "      <td>Ruby</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ill-inc / biomes-game</td>\n",
       "      <td>Biomes is an open source sandbox MMORPG built ...</td>\n",
       "      <td>8</td>\n",
       "      <td>TypeScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1Panel-dev / 1Panel</td>\n",
       "      <td>üî• üî• üî• Áé∞‰ª£Âåñ„ÄÅÂºÄÊ∫êÁöÑ Linux ÊúçÂä°Âô®ËøêÁª¥ÁÆ°ÁêÜÈù¢Êùø„ÄÇ</td>\n",
       "      <td>29</td>\n",
       "      <td>Go</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>taojy123 / KeymouseGo</td>\n",
       "      <td>Á±ª‰ººÊåâÈîÆÁ≤æÁÅµÁöÑÈº†Ê†áÈîÆÁõòÂΩïÂà∂ÂíåËá™Âä®ÂåñÊìç‰Ωú Ê®°ÊãüÁÇπÂáªÂíåÈîÆÂÖ• | automate mouse c...</td>\n",
       "      <td></td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>jiran214 / GPT-vup</td>\n",
       "      <td>GPT-vup BIliBili | ÊäñÈü≥ | AI | ËôöÊãü‰∏ªÊí≠</td>\n",
       "      <td>-</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>SkyAsor / JavaScript-DEX-Triangular-Arbitrage-...</td>\n",
       "      <td>Save time and maximize your profits with our J...</td>\n",
       "      <td>-</td>\n",
       "      <td>Built by</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>bellard / quickjs</td>\n",
       "      <td>Public repository of the QuickJS Javascript En...</td>\n",
       "      <td>-</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>rany2 / edge-tts</td>\n",
       "      <td>Use Microsoft Edge's online text-to-speech ser...</td>\n",
       "      <td>-</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ibaiw / 2023Hvv</td>\n",
       "      <td>2023 HVVÊÉÖÊä•ÈÄüÈÄí~</td>\n",
       "      <td>-</td>\n",
       "      <td>Built by</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>wangshusen / SearchEngine</td>\n",
       "      <td>ÊêúÁ¥¢ÂºïÊìéÂéüÁêÜ</td>\n",
       "      <td>-</td>\n",
       "      <td>Built by</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>diegomura / react-pdf</td>\n",
       "      <td>üìÑ Create PDF files using React</td>\n",
       "      <td></td>\n",
       "      <td>JavaScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>roboflow / supervision</td>\n",
       "      <td>We write your reusable computer vision tools. üíú</td>\n",
       "      <td>452</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>xxlllq / system_architect</td>\n",
       "      <td>üíØ2023Âπ¥Á≥ªÁªüÊû∂ÊûÑËÆæËÆ°Â∏àÔºàËΩØËÄÉÈ´òÁ∫ßÔºâÂ§áËÄÉËµÑÊñô„ÄÇ</td>\n",
       "      <td>-</td>\n",
       "      <td>HTML</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>opentffoundation / manifesto</td>\n",
       "      <td>The OpenTF Manifesto expresses concern over Ha...</td>\n",
       "      <td>-</td>\n",
       "      <td>HTML</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Kotlin / kotlinx.serialization</td>\n",
       "      <td>Kotlin multiplatform / multi-format serialization</td>\n",
       "      <td>149</td>\n",
       "      <td>Kotlin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>novuhq / novu</td>\n",
       "      <td>The open-source notification infrastructure wi...</td>\n",
       "      <td>316</td>\n",
       "      <td>TypeScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>apitable / apitable</td>\n",
       "      <td>üöÄüéâüìö APITable, an API-oriented low-code platfor...</td>\n",
       "      <td></td>\n",
       "      <td>TypeScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>ververica / flink-cdc-connectors</td>\n",
       "      <td>CDC Connectors for Apache Flink¬Æ</td>\n",
       "      <td>11</td>\n",
       "      <td>Java</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>lllyasviel / Fooocus</td>\n",
       "      <td>Focus on prompting and generating</td>\n",
       "      <td>3</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Repository title  \\\n",
       "0                               getumbrel / llama-gpt   \n",
       "1               elidianaandrade / dio-lab-open-source   \n",
       "2                                  apple / ml-fastvit   \n",
       "3                                     alibaba / canal   \n",
       "4                                 LorisYounger / VPet   \n",
       "5                                     systeminit / si   \n",
       "6                                 ubicloud / ubicloud   \n",
       "7                               ill-inc / biomes-game   \n",
       "8                                 1Panel-dev / 1Panel   \n",
       "9                               taojy123 / KeymouseGo   \n",
       "10                                 jiran214 / GPT-vup   \n",
       "11  SkyAsor / JavaScript-DEX-Triangular-Arbitrage-...   \n",
       "12                                  bellard / quickjs   \n",
       "13                                   rany2 / edge-tts   \n",
       "14                                    ibaiw / 2023Hvv   \n",
       "15                          wangshusen / SearchEngine   \n",
       "16                              diegomura / react-pdf   \n",
       "17                             roboflow / supervision   \n",
       "18                          xxlllq / system_architect   \n",
       "19                       opentffoundation / manifesto   \n",
       "20                     Kotlin / kotlinx.serialization   \n",
       "21                                      novuhq / novu   \n",
       "22                                apitable / apitable   \n",
       "23                   ververica / flink-cdc-connectors   \n",
       "24                               lllyasviel / Fooocus   \n",
       "\n",
       "                               Repository description Contributor    Language  \n",
       "0   A self-hosted, offline, ChatGPT-like chatbot. ...           -  TypeScript  \n",
       "1   Reposit√≥rio do lab Contribuindo em um Projeto ...           -    Built by  \n",
       "2   This repository contains the official implemen...           2      Python  \n",
       "3                         ÈòøÈáåÂ∑¥Â∑¥ MySQL binlog Â¢ûÈáèËÆ¢ÈòÖ&Ê∂àË¥πÁªÑ‰ª∂           2        Java  \n",
       "4                   ËôöÊãüÊ°åÂÆ†Ê®°ÊãüÂô® ‰∏Ä‰∏™ÂºÄÊ∫êÁöÑÊ°åÂÆ†ËΩØ‰ª∂, ÂèØ‰ª•ÂÜÖÁΩÆÂà∞‰ªª‰ΩïWPFÂ∫îÁî®Á®ãÂ∫è           1          C#  \n",
       "5                      The System Initiative software           -        Rust  \n",
       "6   Open, free, and portable cloud. Elastic comput...           8        Ruby  \n",
       "7   Biomes is an open source sandbox MMORPG built ...           8  TypeScript  \n",
       "8                      üî• üî• üî• Áé∞‰ª£Âåñ„ÄÅÂºÄÊ∫êÁöÑ Linux ÊúçÂä°Âô®ËøêÁª¥ÁÆ°ÁêÜÈù¢Êùø„ÄÇ          29          Go  \n",
       "9   Á±ª‰ººÊåâÈîÆÁ≤æÁÅµÁöÑÈº†Ê†áÈîÆÁõòÂΩïÂà∂ÂíåËá™Âä®ÂåñÊìç‰Ωú Ê®°ÊãüÁÇπÂáªÂíåÈîÆÂÖ• | automate mouse c...                  Python  \n",
       "10                  GPT-vup BIliBili | ÊäñÈü≥ | AI | ËôöÊãü‰∏ªÊí≠           -      Python  \n",
       "11  Save time and maximize your profits with our J...           -    Built by  \n",
       "12  Public repository of the QuickJS Javascript En...           -           C  \n",
       "13  Use Microsoft Edge's online text-to-speech ser...           -      Python  \n",
       "14                                      2023 HVVÊÉÖÊä•ÈÄüÈÄí~           -    Built by  \n",
       "15                                             ÊêúÁ¥¢ÂºïÊìéÂéüÁêÜ           -    Built by  \n",
       "16                     üìÑ Create PDF files using React              JavaScript  \n",
       "17    We write your reusable computer vision tools. üíú         452      Python  \n",
       "18                           üíØ2023Âπ¥Á≥ªÁªüÊû∂ÊûÑËÆæËÆ°Â∏àÔºàËΩØËÄÉÈ´òÁ∫ßÔºâÂ§áËÄÉËµÑÊñô„ÄÇ           -        HTML  \n",
       "19  The OpenTF Manifesto expresses concern over Ha...           -        HTML  \n",
       "20  Kotlin multiplatform / multi-format serialization         149      Kotlin  \n",
       "21  The open-source notification infrastructure wi...         316  TypeScript  \n",
       "22  üöÄüéâüìö APITable, an API-oriented low-code platfor...              TypeScript  \n",
       "23                   CDC Connectors for Apache Flink¬Æ          11        Java  \n",
       "24                  Focus on prompting and generating           3      Python  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df4=pd.DataFrame({'Repository title': Repository_title,\n",
    "                  'Repository description': Repository_description,\n",
    "                  'Contributor': Contributor,\n",
    "                  'Language': Language})\n",
    "\n",
    "df4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9879071",
   "metadata": {},
   "source": [
    "# Question No-8 UCI Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a8cf83c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome()\n",
    "driver.get('https://archive.ics.uci.edu/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f2c16513",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets click the all set details\n",
    "\n",
    "Dataset=driver.find_element(By.XPATH,'/html/body/div/div[1]/div[1]/main/div/div[1]/div/div/div/a[1]')\n",
    "Dataset.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "41286772",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets scrape the url and Contributor count\n",
    "product_url2=[]\n",
    "\n",
    "url1=driver.find_elements(By.XPATH,'//a[@class=\"link-hover link text-xl font-semibold\"]')\n",
    "for ii in url1:\n",
    "    product_url2.append(ii.get_attribute('href'))\n",
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "05484dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets scrape the DataSet Name\n",
    "Dataset_Name=[]\n",
    "\n",
    "for url in product_url2:\n",
    "    driver.get(url)\n",
    "    time.sleep(3)\n",
    "    try:\n",
    "        Dataset=driver.find_element(By.XPATH,'//h1[@class=\"text-3xl font-semibold text-primary-content\"]')\n",
    "        Dataset_Name.append(Dataset.text)\n",
    "    except NoSuchElementException:\n",
    "        Dataset_Name.append('-')\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "#lets scrape the DataSet Type\n",
    "\n",
    "Dataset_type=[]\n",
    "\n",
    "for url in product_url2:\n",
    "    driver.get(url)\n",
    "    time.sleep(3)\n",
    "    try:\n",
    "        Datatype=driver.find_element(By.XPATH,'//div[@class=\"relative flex flex-col gap-4 bg-base-100 p-4 shadow\"]/div[2]/div[1]/p[1]')\n",
    "        Dataset_type.append(Datatype.text)\n",
    "    except NoSuchElementException:\n",
    "        Dataset_type.append('-')\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "#lets scrape the DataSet task\n",
    "\n",
    "Dataset_task=[]\n",
    "\n",
    "for url in product_url2:\n",
    "    driver.get(url)\n",
    "    time.sleep(3)\n",
    "    try:\n",
    "        Datatask=driver.find_element(By.XPATH,'//div[@class=\"relative flex flex-col gap-4 bg-base-100 p-4 shadow\"]/div[2]/div[3]/p[1]')\n",
    "        Dataset_task.append(Datatask.text)\n",
    "    except NoSuchElementException:\n",
    "        Dataset_task.append('-')\n",
    "        \n",
    "        \n",
    "        \n",
    "#lets scrape the Attribute Type\n",
    "\n",
    "Attribute_type=[]\n",
    "\n",
    "for url in product_url2:\n",
    "    driver.get(url)\n",
    "    time.sleep(3)\n",
    "    try:\n",
    "        Attribute=driver.find_element(By.XPATH,'//div[@class=\"relative flex flex-col gap-4 bg-base-100 p-4 shadow\"]/div[2]/div[4]/p[1]')\n",
    "        Attribute_type.append(Attribute.text)\n",
    "    except NoSuchElementException:\n",
    "        Attribute_type.append('-')\n",
    "        \n",
    "        \n",
    "        \n",
    "#lets scrape the No of Instances\n",
    "\n",
    "No_Instances=[]\n",
    "\n",
    "for url in product_url2:\n",
    "    driver.get(url)\n",
    "    time.sleep(3)\n",
    "    try:\n",
    "        insta=driver.find_element(By.XPATH,'//div[@class=\"relative flex flex-col gap-4 bg-base-100 p-4 shadow\"]/div[2]/div[5]/p[1]')\n",
    "        No_Instances.append(insta.text)\n",
    "    except NoSuchElementException:\n",
    "        No_Instances.append('-')\n",
    "        \n",
    "        \n",
    "        \n",
    "#lets scrape the No of Attribute\n",
    "\n",
    "No_Attributes=[]\n",
    "\n",
    "for url in product_url2:\n",
    "    driver.get(url)\n",
    "    time.sleep(3)\n",
    "    try:\n",
    "        att=driver.find_element(By.XPATH,'//div[@class=\"relative flex flex-col gap-4 bg-base-100 p-4 shadow\"]/div[2]/div[6]/p[1]')\n",
    "        No_Attributes.append(att.text)\n",
    "    except NoSuchElementException:\n",
    "        No_Attributes.append('-')\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "#lets scrape the Date\n",
    "\n",
    "Date=[]\n",
    "\n",
    "for url in product_url2:\n",
    "    driver.get(url)\n",
    "    time.sleep(3)\n",
    "    try:\n",
    "        date=driver.find_element(By.XPATH,'//div[@class=\"relative flex flex w-full items-center gap-4 bg-primary p-2\"]/div[2]/h2[1]')\n",
    "        Date.append(date.text)\n",
    "    except NoSuchElementException:\n",
    "        Date.append('-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8ef55bd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dateset Name</th>\n",
       "      <th>Dataset Type</th>\n",
       "      <th>Dataset task</th>\n",
       "      <th>Attribute type</th>\n",
       "      <th>No of Attributes</th>\n",
       "      <th>No of Instances</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Iris</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Real</td>\n",
       "      <td>4</td>\n",
       "      <td>150</td>\n",
       "      <td>Donated on 6/30/1988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Heart Disease</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer, Real</td>\n",
       "      <td>13</td>\n",
       "      <td>303</td>\n",
       "      <td>Donated on 6/30/1988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Adult</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer</td>\n",
       "      <td>14</td>\n",
       "      <td>48842</td>\n",
       "      <td>Donated on 4/30/1996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dry Bean Dataset</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Integer, Real</td>\n",
       "      <td>16</td>\n",
       "      <td>13611</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Diabetes</td>\n",
       "      <td>Multivariate, Time-Series</td>\n",
       "      <td>-</td>\n",
       "      <td>Categorical, Integer</td>\n",
       "      <td>20</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Wine</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Integer, Real</td>\n",
       "      <td>13</td>\n",
       "      <td>178</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Breast Cancer Wisconsin (Diagnostic)</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Real</td>\n",
       "      <td>30</td>\n",
       "      <td>569</td>\n",
       "      <td>Donated on 10/31/1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Rice (Cammeo and Osmancik)</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Real</td>\n",
       "      <td>8</td>\n",
       "      <td>3810</td>\n",
       "      <td>Donated on 10/5/2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Car Evaluation</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical</td>\n",
       "      <td>6</td>\n",
       "      <td>1728</td>\n",
       "      <td>Donated on 5/31/1997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Mushroom</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical</td>\n",
       "      <td>22</td>\n",
       "      <td>8124</td>\n",
       "      <td>Donated on 4/26/1987</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Dateset Name               Dataset Type  \\\n",
       "0                                  Iris               Multivariate   \n",
       "1                         Heart Disease               Multivariate   \n",
       "2                                 Adult               Multivariate   \n",
       "3                      Dry Bean Dataset               Multivariate   \n",
       "4                              Diabetes  Multivariate, Time-Series   \n",
       "5                                  Wine               Multivariate   \n",
       "6  Breast Cancer Wisconsin (Diagnostic)               Multivariate   \n",
       "7            Rice (Cammeo and Osmancik)               Multivariate   \n",
       "8                        Car Evaluation               Multivariate   \n",
       "9                              Mushroom               Multivariate   \n",
       "\n",
       "     Dataset task              Attribute type No of Attributes  \\\n",
       "0  Classification                        Real                4   \n",
       "1  Classification  Categorical, Integer, Real               13   \n",
       "2  Classification        Categorical, Integer               14   \n",
       "3  Classification               Integer, Real               16   \n",
       "4               -        Categorical, Integer               20   \n",
       "5  Classification               Integer, Real               13   \n",
       "6  Classification                        Real               30   \n",
       "7  Classification                        Real                8   \n",
       "8  Classification                 Categorical                6   \n",
       "9  Classification                 Categorical               22   \n",
       "\n",
       "  No of Instances                   Date  \n",
       "0             150   Donated on 6/30/1988  \n",
       "1             303   Donated on 6/30/1988  \n",
       "2           48842   Donated on 4/30/1996  \n",
       "3           13611                      -  \n",
       "4               -                      -  \n",
       "5             178                      -  \n",
       "6             569  Donated on 10/31/1995  \n",
       "7            3810   Donated on 10/5/2019  \n",
       "8            1728   Donated on 5/31/1997  \n",
       "9            8124   Donated on 4/26/1987  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df5=pd.DataFrame({'Dateset Name':Dataset_Name,'Dataset Type':Dataset_type,'Dataset task': Dataset_task,'Attribute type':Attribute_type,'No of Attributes':No_Attributes,\n",
    "                 'No of Instances':No_Instances,'Date': Date})\n",
    "df5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daa88296",
   "metadata": {},
   "source": [
    "# Question No 5---Billboard Hot 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a9b7c929",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome()\n",
    "driver.get('https://www.billboard.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "961529c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets click the Chart \n",
    "\n",
    "chart=driver.find_element(By.XPATH,'/html/body/div[3]/header/div/div[2]/div/div/div[2]/div[2]/div/div/nav/ul/li[2]/a')\n",
    "chart.click()\n",
    "\n",
    "\n",
    "Allchart=driver.find_element(By.XPATH,'/html/body/div[3]/main/div[2]/div[1]/div[1]/div/div/div[3]/a')\n",
    "Allchart.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5cf50fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets scrape the Song Name\n",
    "\n",
    "Song_Name=[]\n",
    "\n",
    "name=driver.find_elements(By.XPATH,'//li[@class=\"lrv-u-width-100p\"]/ul[1]/li[1]/h3[1]')\n",
    "\n",
    "for aa in name:\n",
    "    name1=aa.text\n",
    "    Song_Name.append(name1)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "#lets scrape the Artist Name\n",
    "\n",
    "Artist_Name=[]\n",
    "\n",
    "art=driver.find_elements(By.XPATH,'//li[@class=\"lrv-u-width-100p\"]/ul[1]/li[1]/span[1]')\n",
    "\n",
    "for bb in art:\n",
    "    art1=bb.text\n",
    "    Artist_Name.append(art1)\n",
    "    \n",
    "    \n",
    "    \n",
    "#lets scrape the last week rank\n",
    "\n",
    "Rank=[]\n",
    "\n",
    "rank=driver.find_elements(By.XPATH,'//li[@class=\"lrv-u-width-100p\"]/ul[1]/li[4]/span[1]')\n",
    "\n",
    "for cc in rank:\n",
    "    rank1=cc.text\n",
    "    Rank.append(rank1)\n",
    "    \n",
    "    \n",
    "    \n",
    "#lets scrape the peak week rank\n",
    "\n",
    "peak_Rank=[]\n",
    "\n",
    "rank11=driver.find_elements(By.XPATH,'//li[@class=\"lrv-u-width-100p\"]/ul[1]/li[5]/span[1]')\n",
    "\n",
    "for dd in rank11:\n",
    "    rank12=dd.text\n",
    "    peak_Rank.append(rank12)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "#lets scrape the Weeks on board\n",
    "\n",
    "Week_board=[]\n",
    "\n",
    "board=driver.find_elements(By.XPATH,'//li[@class=\"lrv-u-width-100p\"]/ul[1]/li[6]/span[1]')\n",
    "\n",
    "for ee in board:\n",
    "    board1=ee.text\n",
    "    Week_board.append(board1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f84e5040",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Song name</th>\n",
       "      <th>Artist name</th>\n",
       "      <th>Last week rank</th>\n",
       "      <th>Peak rank</th>\n",
       "      <th>Weeks on board</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Last Night</td>\n",
       "      <td>Morgan Wallen</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fast Car</td>\n",
       "      <td>Luke Combs</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cruel Summer</td>\n",
       "      <td>Taylor Swift</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Calm Down</td>\n",
       "      <td>Rema &amp; Selena Gomez</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fukumean</td>\n",
       "      <td>Gunna</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Lagunas</td>\n",
       "      <td>Peso Pluma &amp; Jasiel Nunez</td>\n",
       "      <td>-</td>\n",
       "      <td>77</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Overdrive</td>\n",
       "      <td>Post Malone</td>\n",
       "      <td>68</td>\n",
       "      <td>47</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Bzrp Music Sessions, Vol. 55</td>\n",
       "      <td>Bizarrap &amp; Peso Pluma</td>\n",
       "      <td>99</td>\n",
       "      <td>31</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Dawns</td>\n",
       "      <td>Zach Bryan Featuring Maggie Rogers</td>\n",
       "      <td>-</td>\n",
       "      <td>42</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Rubicon</td>\n",
       "      <td>Peso Pluma</td>\n",
       "      <td>-</td>\n",
       "      <td>63</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows √ó 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Song name                         Artist name  \\\n",
       "0                     Last Night                       Morgan Wallen   \n",
       "1                       Fast Car                          Luke Combs   \n",
       "2                   Cruel Summer                        Taylor Swift   \n",
       "3                      Calm Down                 Rema & Selena Gomez   \n",
       "4                       Fukumean                               Gunna   \n",
       "..                           ...                                 ...   \n",
       "95                       Lagunas           Peso Pluma & Jasiel Nunez   \n",
       "96                     Overdrive                         Post Malone   \n",
       "97  Bzrp Music Sessions, Vol. 55               Bizarrap & Peso Pluma   \n",
       "98                         Dawns  Zach Bryan Featuring Maggie Rogers   \n",
       "99                       Rubicon                          Peso Pluma   \n",
       "\n",
       "   Last week rank Peak rank Weeks on board  \n",
       "0               1         1             28  \n",
       "1               2         2             20  \n",
       "2               4         3             14  \n",
       "3               6         3             49  \n",
       "4               7         4              8  \n",
       "..            ...       ...            ...  \n",
       "95              -        77              6  \n",
       "96             68        47              3  \n",
       "97             99        31             10  \n",
       "98              -        42             15  \n",
       "99              -        63              6  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df6=pd.DataFrame({'Song name':Song_Name,\n",
    "                 'Artist name':Artist_Name,\n",
    "                 'Last week rank':Rank,\n",
    "                 'Peak rank':peak_Rank,\n",
    "                 'Weeks on board':Week_board})\n",
    "df6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59c95862",
   "metadata": {},
   "source": [
    "# Question No 1----Wikipedia Youtube video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8e9bae75",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome()\n",
    "driver.get('https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "87a0c7f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets scrape the Rank\n",
    "\n",
    "YRank=[]\n",
    "\n",
    "yrank=driver.find_elements(By.XPATH,'//table[@class=\"wikitable sortable jquery-tablesorter\"]/tbody[1]/tr/td[1]')\n",
    "\n",
    "for a11 in yrank:\n",
    "    yran=a11.text\n",
    "    YRank.append(yran)\n",
    "    \n",
    "    \n",
    "    \n",
    "#lets scrape the VideoName\n",
    "\n",
    "Vname1=[]\n",
    "\n",
    "vname=driver.find_elements(By.XPATH,'//table[@class=\"wikitable sortable jquery-tablesorter\"]/tbody[1]/tr/td[2]/a[1]')\n",
    "\n",
    "for b11 in vname:\n",
    "    name=b11.text\n",
    "    Vname1.append(name)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "#lets scrape the Video Artist\n",
    "\n",
    "Vartist=[]\n",
    "\n",
    "vart=driver.find_elements(By.XPATH,'//table[@class=\"wikitable sortable jquery-tablesorter\"]/tbody[1]/tr/td[3]')\n",
    "\n",
    "for c11 in vart:\n",
    "    art=c11.text\n",
    "    Vartist.append(art)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "#lets scrape the Upload date\n",
    "\n",
    "Vdate=[]\n",
    "\n",
    "vdat=driver.find_elements(By.XPATH,'//table[@class=\"wikitable sortable jquery-tablesorter\"]/tbody[1]/tr/td[5]')\n",
    "\n",
    "for d11 in vdat:\n",
    "    art=d11.text\n",
    "    Vdate.append(art)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "#lets scrape the Views\n",
    "\n",
    "Vviews=[]\n",
    "\n",
    "vview=driver.find_elements(By.XPATH,'//table[@class=\"wikitable sortable jquery-tablesorter\"]/tbody[1]/tr/td[4]')\n",
    "\n",
    "for e11 in vview:\n",
    "    art=e11.text\n",
    "    Vviews.append(art)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "Rank= YRank[:30]\n",
    "Name= Vname1[:30]\n",
    "Artist=Vartist[:30]\n",
    "Upload_date= Vdate[:30]\n",
    "Views=Vviews[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d59e8493",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Name</th>\n",
       "      <th>Artist</th>\n",
       "      <th>Upload Date</th>\n",
       "      <th>Views in Billion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.</td>\n",
       "      <td>Baby Shark Dance</td>\n",
       "      <td>Pinkfong Baby Shark - children's songs</td>\n",
       "      <td>June 17, 2016</td>\n",
       "      <td>13.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.</td>\n",
       "      <td>Despacito</td>\n",
       "      <td>Luis Fonsi</td>\n",
       "      <td>January 12, 2017</td>\n",
       "      <td>8.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.</td>\n",
       "      <td>Johny Johny Yes Papa</td>\n",
       "      <td>LooLoo Kids - nursery rhymes</td>\n",
       "      <td>October 8, 2016</td>\n",
       "      <td>6.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.</td>\n",
       "      <td>Shape of You</td>\n",
       "      <td>Cocomelon - nursery rhymes</td>\n",
       "      <td>May 2, 2018</td>\n",
       "      <td>6.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.</td>\n",
       "      <td>See You Again</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>January 30, 2017</td>\n",
       "      <td>6.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.</td>\n",
       "      <td>Wheels on the Bus</td>\n",
       "      <td>Wiz Khalifa</td>\n",
       "      <td>April 6, 2015</td>\n",
       "      <td>5.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7.</td>\n",
       "      <td>Uptown Funk</td>\n",
       "      <td>Cocomelon - nursery rhymes</td>\n",
       "      <td>May 24, 2018</td>\n",
       "      <td>5.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8.</td>\n",
       "      <td>Gangnam Style</td>\n",
       "      <td>ChuChu TV - children's songs</td>\n",
       "      <td>March 6, 2014</td>\n",
       "      <td>5.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9.</td>\n",
       "      <td>Dame Tu Cosita</td>\n",
       "      <td>Mark Ronson</td>\n",
       "      <td>November 19, 2014</td>\n",
       "      <td>5.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10.</td>\n",
       "      <td>Axel F</td>\n",
       "      <td>Miroshka TV - children's songs</td>\n",
       "      <td>February 27, 2018</td>\n",
       "      <td>4.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11.</td>\n",
       "      <td>Sugar</td>\n",
       "      <td>Psy</td>\n",
       "      <td>July 15, 2012</td>\n",
       "      <td>4.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12.</td>\n",
       "      <td>Roar</td>\n",
       "      <td>Get Movies - children's songs</td>\n",
       "      <td>January 31, 2012</td>\n",
       "      <td>4.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13.</td>\n",
       "      <td>Counting Stars</td>\n",
       "      <td>El Chombo</td>\n",
       "      <td>April 5, 2018</td>\n",
       "      <td>4.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14.</td>\n",
       "      <td>Baa Baa Black Sheep</td>\n",
       "      <td>Crazy Frog</td>\n",
       "      <td>June 16, 2009</td>\n",
       "      <td>4.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15.</td>\n",
       "      <td>Sorry</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>January 14, 2015</td>\n",
       "      <td>3.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16.</td>\n",
       "      <td>Waka Waka (This Time for Africa)</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>September 5, 2013</td>\n",
       "      <td>3.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17.</td>\n",
       "      <td>Thinking Out Loud</td>\n",
       "      <td>OneRepublic</td>\n",
       "      <td>May 31, 2013</td>\n",
       "      <td>3.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18.</td>\n",
       "      <td>Lakdi Ki Kathi</td>\n",
       "      <td>Cocomelon - nursery rhymes</td>\n",
       "      <td>June 25, 2018</td>\n",
       "      <td>3.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19.</td>\n",
       "      <td>Dark Horse</td>\n",
       "      <td>Justin Bieber</td>\n",
       "      <td>October 22, 2015</td>\n",
       "      <td>3.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20.</td>\n",
       "      <td>Perfect</td>\n",
       "      <td>Shakira</td>\n",
       "      <td>June 4, 2010</td>\n",
       "      <td>3.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21.</td>\n",
       "      <td>Faded</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>October 7, 2014</td>\n",
       "      <td>3.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22.</td>\n",
       "      <td>Let Her Go</td>\n",
       "      <td>Jingle Toons</td>\n",
       "      <td>June 14, 2018</td>\n",
       "      <td>3.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23.</td>\n",
       "      <td>Humpty the train on a fruits ride</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>February 20, 2014</td>\n",
       "      <td>3.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24.</td>\n",
       "      <td>Girls Like You</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>November 9, 2017</td>\n",
       "      <td>3.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25.</td>\n",
       "      <td>Bailando</td>\n",
       "      <td>Alan Walker</td>\n",
       "      <td>December 3, 2015</td>\n",
       "      <td>3.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26.</td>\n",
       "      <td>Lean On</td>\n",
       "      <td>Passenger</td>\n",
       "      <td>July 25, 2012</td>\n",
       "      <td>3.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27.</td>\n",
       "      <td>Pinkfong Baby Shark - Kids' Songs &amp; Stories</td>\n",
       "      <td>Kiddiestv Hindi - children's songs</td>\n",
       "      <td>January 26, 2018</td>\n",
       "      <td>3.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28.</td>\n",
       "      <td>Luis Fonsi</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>May 31, 2018</td>\n",
       "      <td>3.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29.</td>\n",
       "      <td>Wiz Khalifa</td>\n",
       "      <td>Enrique Iglesias</td>\n",
       "      <td>April 11, 2014</td>\n",
       "      <td>3.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30.</td>\n",
       "      <td>Psy</td>\n",
       "      <td>Major Lazer</td>\n",
       "      <td>March 22, 2015</td>\n",
       "      <td>3.43</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank                                         Name  \\\n",
       "0    1.                             Baby Shark Dance   \n",
       "1    2.                                    Despacito   \n",
       "2    3.                         Johny Johny Yes Papa   \n",
       "3    4.                                 Shape of You   \n",
       "4    5.                                See You Again   \n",
       "5    6.                            Wheels on the Bus   \n",
       "6    7.                                  Uptown Funk   \n",
       "7    8.                                Gangnam Style   \n",
       "8    9.                               Dame Tu Cosita   \n",
       "9   10.                                       Axel F   \n",
       "10  11.                                        Sugar   \n",
       "11  12.                                         Roar   \n",
       "12  13.                               Counting Stars   \n",
       "13  14.                          Baa Baa Black Sheep   \n",
       "14  15.                                        Sorry   \n",
       "15  16.             Waka Waka (This Time for Africa)   \n",
       "16  17.                            Thinking Out Loud   \n",
       "17  18.                               Lakdi Ki Kathi   \n",
       "18  19.                                   Dark Horse   \n",
       "19  20.                                      Perfect   \n",
       "20  21.                                        Faded   \n",
       "21  22.                                   Let Her Go   \n",
       "22  23.            Humpty the train on a fruits ride   \n",
       "23  24.                               Girls Like You   \n",
       "24  25.                                     Bailando   \n",
       "25  26.                                      Lean On   \n",
       "26  27.  Pinkfong Baby Shark - Kids' Songs & Stories   \n",
       "27  28.                                   Luis Fonsi   \n",
       "28  29.                                  Wiz Khalifa   \n",
       "29  30.                                          Psy   \n",
       "\n",
       "                                    Artist        Upload Date Views in Billion  \n",
       "0   Pinkfong Baby Shark - children's songs      June 17, 2016            13.18  \n",
       "1                               Luis Fonsi   January 12, 2017             8.23  \n",
       "2             LooLoo Kids - nursery rhymes    October 8, 2016             6.76  \n",
       "3               Cocomelon - nursery rhymes        May 2, 2018             6.33  \n",
       "4                               Ed Sheeran   January 30, 2017             6.05  \n",
       "5                              Wiz Khalifa      April 6, 2015             5.98  \n",
       "6               Cocomelon - nursery rhymes       May 24, 2018             5.46  \n",
       "7             ChuChu TV - children's songs      March 6, 2014             5.42  \n",
       "8                              Mark Ronson  November 19, 2014             5.00  \n",
       "9           Miroshka TV - children's songs  February 27, 2018             4.94  \n",
       "10                                     Psy      July 15, 2012             4.86  \n",
       "11           Get Movies - children's songs   January 31, 2012             4.55  \n",
       "12                               El Chombo      April 5, 2018             4.41  \n",
       "13                              Crazy Frog      June 16, 2009             4.00  \n",
       "14                                Maroon 5   January 14, 2015             3.91  \n",
       "15                              Katy Perry  September 5, 2013             3.84  \n",
       "16                             OneRepublic       May 31, 2013             3.84  \n",
       "17              Cocomelon - nursery rhymes      June 25, 2018             3.73  \n",
       "18                           Justin Bieber   October 22, 2015             3.69  \n",
       "19                                 Shakira       June 4, 2010             3.68  \n",
       "20                              Ed Sheeran    October 7, 2014             3.63  \n",
       "21                            Jingle Toons      June 14, 2018             3.63  \n",
       "22                              Katy Perry  February 20, 2014             3.56  \n",
       "23                              Ed Sheeran   November 9, 2017             3.51  \n",
       "24                             Alan Walker   December 3, 2015             3.49  \n",
       "25                               Passenger      July 25, 2012             3.48  \n",
       "26      Kiddiestv Hindi - children's songs   January 26, 2018             3.51  \n",
       "27                                Maroon 5       May 31, 2018             3.45  \n",
       "28                        Enrique Iglesias     April 11, 2014             3.43  \n",
       "29                             Major Lazer     March 22, 2015             3.43  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df7=pd.DataFrame({'Rank':Rank,\n",
    "                 'Name': Name,\n",
    "                 'Artist': Artist,\n",
    "                 'Upload Date':Upload_date,\n",
    "                 'Views in Billion':Views})\n",
    "df7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb72dd89",
   "metadata": {},
   "source": [
    "# Question No- 06 - Highest Selling Novels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3bd635a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets go to the website\n",
    "\n",
    "driver=webdriver.Chrome()\n",
    "driver.get('https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "486aabc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets extract the title of Novel\n",
    "\n",
    "Novel_Title=[]\n",
    "\n",
    "Ntitle=driver.find_elements(By.XPATH,'//table[@class=\"in-article sortable\"]/tbody[1]/tr/td[2]')\n",
    "\n",
    "for a20 in Ntitle:\n",
    "    ntit=a20.text\n",
    "    Novel_Title.append(ntit)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "#Lets extract the Author Nanme\n",
    "\n",
    "Author_Name=[]\n",
    "\n",
    "Aname=driver.find_elements(By.XPATH,'//table[@class=\"in-article sortable\"]/tbody[1]/tr/td[3]')\n",
    "\n",
    "for b20 in Aname:\n",
    "    Aname1=b20.text\n",
    "    Author_Name.append(Aname1)\n",
    "    \n",
    "    \n",
    "    \n",
    "#Lets extract the Volume Sold\n",
    "\n",
    "Volume=[]\n",
    "\n",
    "vol=driver.find_elements(By.XPATH,'//table[@class=\"in-article sortable\"]/tbody[1]/tr/td[4]')\n",
    "\n",
    "for c20 in vol:\n",
    "    vol1=c20.text\n",
    "    Volume.append(vol1)\n",
    "    \n",
    "    \n",
    "    \n",
    "#Lets extract the Publisher\n",
    "\n",
    "Publisher=[]\n",
    "\n",
    "pub=driver.find_elements(By.XPATH,'//table[@class=\"in-article sortable\"]/tbody[1]/tr/td[5]')\n",
    "\n",
    "for d20 in pub:\n",
    "    pub1=d20.text\n",
    "    Publisher.append(pub1)\n",
    "    \n",
    "    \n",
    "    \n",
    "#Lets extract the Genre\n",
    "\n",
    "Genre=[]\n",
    "\n",
    "gen=driver.find_elements(By.XPATH,'//table[@class=\"in-article sortable\"]/tbody[1]/tr/td[6]')\n",
    "\n",
    "for e20 in gen:\n",
    "    gen1=e20.text\n",
    "    Genre.append(gen1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "53e2938d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Book name</th>\n",
       "      <th>Author name</th>\n",
       "      <th>Volumes sold</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Da Vinci Code,The</td>\n",
       "      <td>Brown, Dan</td>\n",
       "      <td>5,094,805</td>\n",
       "      <td>Transworld</td>\n",
       "      <td>Crime, Thriller &amp; Adventure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Harry Potter and the Deathly Hallows</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,475,152</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Harry Potter and the Philosopher's Stone</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,200,654</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Harry Potter and the Order of the Phoenix</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,179,479</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fifty Shades of Grey</td>\n",
       "      <td>James, E. L.</td>\n",
       "      <td>3,758,936</td>\n",
       "      <td>Random House</td>\n",
       "      <td>Romance &amp; Sagas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Ghost,The</td>\n",
       "      <td>Harris, Robert</td>\n",
       "      <td>807,311</td>\n",
       "      <td>Random House</td>\n",
       "      <td>General &amp; Literary Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Happy Days with the Naked Chef</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>794,201</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Hunger Games,The:Hunger Games Trilogy</td>\n",
       "      <td>Collins, Suzanne</td>\n",
       "      <td>792,187</td>\n",
       "      <td>Scholastic Ltd.</td>\n",
       "      <td>Young Adult Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Lost Boy,The:A Foster Child's Search for the L...</td>\n",
       "      <td>Pelzer, Dave</td>\n",
       "      <td>791,507</td>\n",
       "      <td>Orion</td>\n",
       "      <td>Biography: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Jamie's Ministry of Food:Anyone Can Learn to C...</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>791,095</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows √ó 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Book name       Author name  \\\n",
       "0                                   Da Vinci Code,The        Brown, Dan   \n",
       "1                Harry Potter and the Deathly Hallows     Rowling, J.K.   \n",
       "2            Harry Potter and the Philosopher's Stone     Rowling, J.K.   \n",
       "3           Harry Potter and the Order of the Phoenix     Rowling, J.K.   \n",
       "4                                Fifty Shades of Grey      James, E. L.   \n",
       "..                                                ...               ...   \n",
       "95                                          Ghost,The    Harris, Robert   \n",
       "96                     Happy Days with the Naked Chef     Oliver, Jamie   \n",
       "97              Hunger Games,The:Hunger Games Trilogy  Collins, Suzanne   \n",
       "98  Lost Boy,The:A Foster Child's Search for the L...      Pelzer, Dave   \n",
       "99  Jamie's Ministry of Food:Anyone Can Learn to C...     Oliver, Jamie   \n",
       "\n",
       "   Volumes sold        Publisher                        Genre  \n",
       "0     5,094,805       Transworld  Crime, Thriller & Adventure  \n",
       "1     4,475,152       Bloomsbury           Children's Fiction  \n",
       "2     4,200,654       Bloomsbury           Children's Fiction  \n",
       "3     4,179,479       Bloomsbury           Children's Fiction  \n",
       "4     3,758,936     Random House              Romance & Sagas  \n",
       "..          ...              ...                          ...  \n",
       "95      807,311     Random House   General & Literary Fiction  \n",
       "96      794,201          Penguin        Food & Drink: General  \n",
       "97      792,187  Scholastic Ltd.          Young Adult Fiction  \n",
       "98      791,507            Orion           Biography: General  \n",
       "99      791,095          Penguin        Food & Drink: General  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df8=pd.DataFrame({'Book name':Novel_Title,'Author name':Author_Name,'Volumes sold':Volume,'Publisher':Publisher,'Genre':Genre})\n",
    "df8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf77604",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
